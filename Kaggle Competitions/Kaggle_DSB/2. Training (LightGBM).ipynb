{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "train_labels = pd.read_csv('./data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_session</th>\n",
       "      <th>installation_id</th>\n",
       "      <th>title</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_incorrect</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6bdf9623adc94d89</td>\n",
       "      <td>0006a69f</td>\n",
       "      <td>Mushroom Sorter (Assessment)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>77b8ee947eb84b4e</td>\n",
       "      <td>0006a69f</td>\n",
       "      <td>Bird Measurer (Assessment)</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>901acc108f55a5a1</td>\n",
       "      <td>0006a69f</td>\n",
       "      <td>Mushroom Sorter (Assessment)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9501794defd84e4d</td>\n",
       "      <td>0006a69f</td>\n",
       "      <td>Mushroom Sorter (Assessment)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a9ef3ecb3d1acc6a</td>\n",
       "      <td>0006a69f</td>\n",
       "      <td>Bird Measurer (Assessment)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_session installation_id                         title  \\\n",
       "0  6bdf9623adc94d89        0006a69f  Mushroom Sorter (Assessment)   \n",
       "1  77b8ee947eb84b4e        0006a69f    Bird Measurer (Assessment)   \n",
       "2  901acc108f55a5a1        0006a69f  Mushroom Sorter (Assessment)   \n",
       "3  9501794defd84e4d        0006a69f  Mushroom Sorter (Assessment)   \n",
       "4  a9ef3ecb3d1acc6a        0006a69f    Bird Measurer (Assessment)   \n",
       "\n",
       "   num_correct  num_incorrect  accuracy  accuracy_group  \n",
       "0            1              0       1.0               3  \n",
       "1            0             11       0.0               0  \n",
       "2            1              0       1.0               3  \n",
       "3            1              1       0.5               2  \n",
       "4            1              0       1.0               3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['dayofweek'] = df['timestamp'].dt.dayofweek  \n",
    "    return df\n",
    "    \n",
    "def get_object_columns(df, columns):\n",
    "    df = df.groupby(['installation_id', columns])['event_id'].count().reset_index()\n",
    "    df = df.pivot_table(index = 'installation_id', columns = [columns], values = 'event_id')\n",
    "    df.columns = list(df.columns)\n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "def get_numeric_columns(df, column):\n",
    "    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std']})\n",
    "    df.fillna(0, inplace = True)\n",
    "    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std']\n",
    "    return df\n",
    "\n",
    "def get_numeric_columns_add(df, agg_column, column):\n",
    "    df = df.groupby(['installation_id', agg_column]).agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std']}).reset_index()\n",
    "    df = df.pivot_table(index = 'installation_id', columns = [agg_column], values = [col for col in df.columns if col not in ['installation_id', 'type']])\n",
    "    df.fillna(0, inplace = True)\n",
    "    df.columns = list(df.columns)\n",
    "    return df\n",
    "\n",
    "def perform_features_engineering(train_df, test_df, train_labels_df):\n",
    "    print(f'Perform features engineering')\n",
    "    numerical_columns = ['game_time']\n",
    "    categorical_columns = ['type', 'world']\n",
    "\n",
    "    comp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})\n",
    "    comp_train_df.set_index('installation_id', inplace = True)\n",
    "    comp_test_df = pd.DataFrame({'installation_id': test_df['installation_id'].unique()})\n",
    "    comp_test_df.set_index('installation_id', inplace = True)\n",
    "\n",
    "    test_df = extract_time_features(test_df)\n",
    "    train_df = extract_time_features(train_df)\n",
    "\n",
    "    for i in numerical_columns:\n",
    "        comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, i), left_index = True, right_index = True)\n",
    "        comp_test_df = comp_test_df.merge(get_numeric_columns(test_df, i), left_index = True, right_index = True)\n",
    "    \n",
    "    for i in categorical_columns:\n",
    "        comp_train_df = comp_train_df.merge(get_object_columns(train_df, i), left_index = True, right_index = True)\n",
    "        comp_test_df = comp_test_df.merge(get_object_columns(test_df, i), left_index = True, right_index = True)\n",
    "    \n",
    "    for i in categorical_columns:\n",
    "        for j in numerical_columns:\n",
    "            comp_train_df = comp_train_df.merge(get_numeric_columns_add(train_df, i, j), left_index = True, right_index = True)\n",
    "            comp_test_df = comp_test_df.merge(get_numeric_columns_add(test_df, i, j), left_index = True, right_index = True)\n",
    "    \n",
    "    \n",
    "    comp_train_df.reset_index(inplace = True)\n",
    "    comp_test_df.reset_index(inplace = True)\n",
    "    \n",
    "    print('Our training set have {} rows and {} columns'.format(comp_train_df.shape[0], comp_train_df.shape[1]))\n",
    "\n",
    "    # get the mode of the title\n",
    "    labels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0]))\n",
    "    # merge target\n",
    "    labels = train_labels_df[['installation_id', 'title', 'accuracy_group']]\n",
    "    # replace title with the mode\n",
    "    labels['title'] = labels['title'].map(labels_map)\n",
    "    # get title from the test set\n",
    "    comp_test_df['title'] = test_df.groupby('installation_id').last()['title'].map(labels_map).reset_index(drop = True)\n",
    "    # join train with labels\n",
    "    comp_train_df = labels.merge(comp_train_df, on = 'installation_id', how = 'left')\n",
    "    print('We have {} training rows'.format(comp_train_df.shape[0]))\n",
    "    \n",
    "    return comp_train_df, comp_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform features engineering\n",
      "Our training set have 17000 rows and 54 columns\n",
      "We have 17690 training rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = perform_features_engineering(train, test, train_labels)\n",
    "del train, test, train_labels; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in train_df.columns if col not in ['installation_id', 'accuracy_group']]\n",
    "X, y, X_test= train_df.loc[:,x_cols].values, train_df['accuracy_group'].values, test_df.loc[:,x_cols].values\n",
    "test_sub = test_df[['installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':2000,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'subsample': 0.75,\n",
    "          'subsample_freq': 1,\n",
    "          'learning_rate': 0.04,\n",
    "          'feature_fraction': 0.9,\n",
    "          'max_depth': 15,\n",
    "          'lambda_l1': 1,  \n",
    "          'lambda_l2': 1,\n",
    "          'verbose': 100,\n",
    "          'early_stopping_rounds': 100\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 1.24717\tvalid_1's rmse: 1.22921\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's rmse: 1.23349\tvalid_1's rmse: 1.21633\n",
      "[3]\ttraining's rmse: 1.22063\tvalid_1's rmse: 1.20397\n",
      "[4]\ttraining's rmse: 1.20858\tvalid_1's rmse: 1.19239\n",
      "[5]\ttraining's rmse: 1.19723\tvalid_1's rmse: 1.18179\n",
      "[6]\ttraining's rmse: 1.18668\tvalid_1's rmse: 1.17179\n",
      "[7]\ttraining's rmse: 1.177\tvalid_1's rmse: 1.16272\n",
      "[8]\ttraining's rmse: 1.16768\tvalid_1's rmse: 1.15398\n",
      "[9]\ttraining's rmse: 1.15879\tvalid_1's rmse: 1.14575\n",
      "[10]\ttraining's rmse: 1.15045\tvalid_1's rmse: 1.13844\n",
      "[11]\ttraining's rmse: 1.14273\tvalid_1's rmse: 1.13157\n",
      "[12]\ttraining's rmse: 1.13548\tvalid_1's rmse: 1.12504\n",
      "[13]\ttraining's rmse: 1.12833\tvalid_1's rmse: 1.11849\n",
      "[14]\ttraining's rmse: 1.12178\tvalid_1's rmse: 1.11276\n",
      "[15]\ttraining's rmse: 1.11565\tvalid_1's rmse: 1.1074\n",
      "[16]\ttraining's rmse: 1.1126\tvalid_1's rmse: 1.10538\n",
      "[17]\ttraining's rmse: 1.10706\tvalid_1's rmse: 1.10066\n",
      "[18]\ttraining's rmse: 1.10182\tvalid_1's rmse: 1.09612\n",
      "[19]\ttraining's rmse: 1.09665\tvalid_1's rmse: 1.09159\n",
      "[20]\ttraining's rmse: 1.09194\tvalid_1's rmse: 1.08751\n",
      "[21]\ttraining's rmse: 1.08739\tvalid_1's rmse: 1.08368\n",
      "[22]\ttraining's rmse: 1.08491\tvalid_1's rmse: 1.08218\n",
      "[23]\ttraining's rmse: 1.0807\tvalid_1's rmse: 1.07863\n",
      "[24]\ttraining's rmse: 1.07657\tvalid_1's rmse: 1.0753\n",
      "[25]\ttraining's rmse: 1.07266\tvalid_1's rmse: 1.07229\n",
      "[26]\ttraining's rmse: 1.06886\tvalid_1's rmse: 1.06943\n",
      "[27]\ttraining's rmse: 1.06533\tvalid_1's rmse: 1.06689\n",
      "[28]\ttraining's rmse: 1.06212\tvalid_1's rmse: 1.06443\n",
      "[29]\ttraining's rmse: 1.05898\tvalid_1's rmse: 1.06178\n",
      "[30]\ttraining's rmse: 1.05674\tvalid_1's rmse: 1.06026\n",
      "[31]\ttraining's rmse: 1.05378\tvalid_1's rmse: 1.05816\n",
      "[32]\ttraining's rmse: 1.05099\tvalid_1's rmse: 1.05596\n",
      "[33]\ttraining's rmse: 1.04825\tvalid_1's rmse: 1.05397\n",
      "[34]\ttraining's rmse: 1.04556\tvalid_1's rmse: 1.05208\n",
      "[35]\ttraining's rmse: 1.04308\tvalid_1's rmse: 1.05037\n",
      "[36]\ttraining's rmse: 1.04066\tvalid_1's rmse: 1.04875\n",
      "[37]\ttraining's rmse: 1.03827\tvalid_1's rmse: 1.0474\n",
      "[38]\ttraining's rmse: 1.03604\tvalid_1's rmse: 1.04595\n",
      "[39]\ttraining's rmse: 1.03424\tvalid_1's rmse: 1.0448\n",
      "[40]\ttraining's rmse: 1.03206\tvalid_1's rmse: 1.04336\n",
      "[41]\ttraining's rmse: 1.03008\tvalid_1's rmse: 1.04218\n",
      "[42]\ttraining's rmse: 1.02818\tvalid_1's rmse: 1.041\n",
      "[43]\ttraining's rmse: 1.02633\tvalid_1's rmse: 1.04011\n",
      "[44]\ttraining's rmse: 1.02448\tvalid_1's rmse: 1.03899\n",
      "[45]\ttraining's rmse: 1.0227\tvalid_1's rmse: 1.03797\n",
      "[46]\ttraining's rmse: 1.02107\tvalid_1's rmse: 1.03721\n",
      "[47]\ttraining's rmse: 1.01947\tvalid_1's rmse: 1.03626\n",
      "[48]\ttraining's rmse: 1.01805\tvalid_1's rmse: 1.0357\n",
      "[49]\ttraining's rmse: 1.01659\tvalid_1's rmse: 1.03482\n",
      "[50]\ttraining's rmse: 1.01512\tvalid_1's rmse: 1.03411\n",
      "[51]\ttraining's rmse: 1.01365\tvalid_1's rmse: 1.03321\n",
      "[52]\ttraining's rmse: 1.01237\tvalid_1's rmse: 1.03227\n",
      "[53]\ttraining's rmse: 1.01094\tvalid_1's rmse: 1.03134\n",
      "[54]\ttraining's rmse: 1.0096\tvalid_1's rmse: 1.03065\n",
      "[55]\ttraining's rmse: 1.00834\tvalid_1's rmse: 1.02978\n",
      "[56]\ttraining's rmse: 1.00711\tvalid_1's rmse: 1.02916\n",
      "[57]\ttraining's rmse: 1.00583\tvalid_1's rmse: 1.02856\n",
      "[58]\ttraining's rmse: 1.00446\tvalid_1's rmse: 1.02801\n",
      "[59]\ttraining's rmse: 1.00336\tvalid_1's rmse: 1.02743\n",
      "[60]\ttraining's rmse: 1.00229\tvalid_1's rmse: 1.02696\n",
      "[61]\ttraining's rmse: 1.00116\tvalid_1's rmse: 1.02637\n",
      "[62]\ttraining's rmse: 1.00011\tvalid_1's rmse: 1.02618\n",
      "[63]\ttraining's rmse: 0.99881\tvalid_1's rmse: 1.02552\n",
      "[64]\ttraining's rmse: 0.99783\tvalid_1's rmse: 1.02509\n",
      "[65]\ttraining's rmse: 0.996634\tvalid_1's rmse: 1.02458\n",
      "[66]\ttraining's rmse: 0.995486\tvalid_1's rmse: 1.02405\n",
      "[67]\ttraining's rmse: 0.994434\tvalid_1's rmse: 1.02345\n",
      "[68]\ttraining's rmse: 0.993481\tvalid_1's rmse: 1.02321\n",
      "[69]\ttraining's rmse: 0.992184\tvalid_1's rmse: 1.02239\n",
      "[70]\ttraining's rmse: 0.991295\tvalid_1's rmse: 1.02216\n",
      "[71]\ttraining's rmse: 0.990178\tvalid_1's rmse: 1.02168\n",
      "[72]\ttraining's rmse: 0.98907\tvalid_1's rmse: 1.02107\n",
      "[73]\ttraining's rmse: 0.988151\tvalid_1's rmse: 1.02078\n",
      "[74]\ttraining's rmse: 0.987343\tvalid_1's rmse: 1.02041\n",
      "[75]\ttraining's rmse: 0.986434\tvalid_1's rmse: 1.01999\n",
      "[76]\ttraining's rmse: 0.985485\tvalid_1's rmse: 1.01981\n",
      "[77]\ttraining's rmse: 0.984629\tvalid_1's rmse: 1.01957\n",
      "[78]\ttraining's rmse: 0.983809\tvalid_1's rmse: 1.01953\n",
      "[79]\ttraining's rmse: 0.982942\tvalid_1's rmse: 1.0192\n",
      "[80]\ttraining's rmse: 0.982092\tvalid_1's rmse: 1.01907\n",
      "[81]\ttraining's rmse: 0.98105\tvalid_1's rmse: 1.01864\n",
      "[82]\ttraining's rmse: 0.980063\tvalid_1's rmse: 1.01817\n",
      "[83]\ttraining's rmse: 0.979249\tvalid_1's rmse: 1.01789\n",
      "[84]\ttraining's rmse: 0.978346\tvalid_1's rmse: 1.01752\n",
      "[85]\ttraining's rmse: 0.977496\tvalid_1's rmse: 1.01724\n",
      "[86]\ttraining's rmse: 0.976551\tvalid_1's rmse: 1.01674\n",
      "[87]\ttraining's rmse: 0.975737\tvalid_1's rmse: 1.01634\n",
      "[88]\ttraining's rmse: 0.974938\tvalid_1's rmse: 1.01621\n",
      "[89]\ttraining's rmse: 0.974252\tvalid_1's rmse: 1.01603\n",
      "[90]\ttraining's rmse: 0.973317\tvalid_1's rmse: 1.01581\n",
      "[91]\ttraining's rmse: 0.972486\tvalid_1's rmse: 1.01554\n",
      "[92]\ttraining's rmse: 0.971528\tvalid_1's rmse: 1.01511\n",
      "[93]\ttraining's rmse: 0.970531\tvalid_1's rmse: 1.01484\n",
      "[94]\ttraining's rmse: 0.969596\tvalid_1's rmse: 1.0147\n",
      "[95]\ttraining's rmse: 0.968708\tvalid_1's rmse: 1.01447\n",
      "[96]\ttraining's rmse: 0.96802\tvalid_1's rmse: 1.01432\n",
      "[97]\ttraining's rmse: 0.967175\tvalid_1's rmse: 1.01396\n",
      "[98]\ttraining's rmse: 0.966402\tvalid_1's rmse: 1.01363\n",
      "[99]\ttraining's rmse: 0.965709\tvalid_1's rmse: 1.01338\n",
      "[100]\ttraining's rmse: 0.964846\tvalid_1's rmse: 1.01286\n",
      "[101]\ttraining's rmse: 0.964005\tvalid_1's rmse: 1.01256\n",
      "[102]\ttraining's rmse: 0.96325\tvalid_1's rmse: 1.01241\n",
      "[103]\ttraining's rmse: 0.962458\tvalid_1's rmse: 1.01217\n",
      "[104]\ttraining's rmse: 0.961548\tvalid_1's rmse: 1.01158\n",
      "[105]\ttraining's rmse: 0.960806\tvalid_1's rmse: 1.01145\n",
      "[106]\ttraining's rmse: 0.960025\tvalid_1's rmse: 1.01123\n",
      "[107]\ttraining's rmse: 0.959293\tvalid_1's rmse: 1.01096\n",
      "[108]\ttraining's rmse: 0.958531\tvalid_1's rmse: 1.01079\n",
      "[109]\ttraining's rmse: 0.957774\tvalid_1's rmse: 1.0107\n",
      "[110]\ttraining's rmse: 0.957017\tvalid_1's rmse: 1.01054\n",
      "[111]\ttraining's rmse: 0.956309\tvalid_1's rmse: 1.01041\n",
      "[112]\ttraining's rmse: 0.955541\tvalid_1's rmse: 1.01033\n",
      "[113]\ttraining's rmse: 0.954823\tvalid_1's rmse: 1.01002\n",
      "[114]\ttraining's rmse: 0.954114\tvalid_1's rmse: 1.00982\n",
      "[115]\ttraining's rmse: 0.953407\tvalid_1's rmse: 1.00953\n",
      "[116]\ttraining's rmse: 0.952623\tvalid_1's rmse: 1.0095\n",
      "[117]\ttraining's rmse: 0.951939\tvalid_1's rmse: 1.00936\n",
      "[118]\ttraining's rmse: 0.951251\tvalid_1's rmse: 1.00916\n",
      "[119]\ttraining's rmse: 0.950519\tvalid_1's rmse: 1.00904\n",
      "[120]\ttraining's rmse: 0.949771\tvalid_1's rmse: 1.00877\n",
      "[121]\ttraining's rmse: 0.949012\tvalid_1's rmse: 1.00861\n",
      "[122]\ttraining's rmse: 0.948297\tvalid_1's rmse: 1.0085\n",
      "[123]\ttraining's rmse: 0.947622\tvalid_1's rmse: 1.00844\n",
      "[124]\ttraining's rmse: 0.946824\tvalid_1's rmse: 1.00824\n",
      "[125]\ttraining's rmse: 0.946006\tvalid_1's rmse: 1.00793\n",
      "[126]\ttraining's rmse: 0.945328\tvalid_1's rmse: 1.00794\n",
      "[127]\ttraining's rmse: 0.944694\tvalid_1's rmse: 1.00796\n",
      "[128]\ttraining's rmse: 0.944032\tvalid_1's rmse: 1.00772\n",
      "[129]\ttraining's rmse: 0.943335\tvalid_1's rmse: 1.0074\n",
      "[130]\ttraining's rmse: 0.942676\tvalid_1's rmse: 1.0072\n",
      "[131]\ttraining's rmse: 0.942037\tvalid_1's rmse: 1.00707\n",
      "[132]\ttraining's rmse: 0.941402\tvalid_1's rmse: 1.00701\n",
      "[133]\ttraining's rmse: 0.940878\tvalid_1's rmse: 1.00706\n",
      "[134]\ttraining's rmse: 0.940244\tvalid_1's rmse: 1.00692\n",
      "[135]\ttraining's rmse: 0.939576\tvalid_1's rmse: 1.0068\n",
      "[136]\ttraining's rmse: 0.939007\tvalid_1's rmse: 1.00668\n",
      "[137]\ttraining's rmse: 0.938361\tvalid_1's rmse: 1.00651\n",
      "[138]\ttraining's rmse: 0.937804\tvalid_1's rmse: 1.00646\n",
      "[139]\ttraining's rmse: 0.937105\tvalid_1's rmse: 1.00622\n",
      "[140]\ttraining's rmse: 0.93646\tvalid_1's rmse: 1.00612\n",
      "[141]\ttraining's rmse: 0.935878\tvalid_1's rmse: 1.00608\n",
      "[142]\ttraining's rmse: 0.93522\tvalid_1's rmse: 1.006\n",
      "[143]\ttraining's rmse: 0.934551\tvalid_1's rmse: 1.00573\n",
      "[144]\ttraining's rmse: 0.933947\tvalid_1's rmse: 1.00559\n",
      "[145]\ttraining's rmse: 0.933454\tvalid_1's rmse: 1.00552\n",
      "[146]\ttraining's rmse: 0.932836\tvalid_1's rmse: 1.00544\n",
      "[147]\ttraining's rmse: 0.932252\tvalid_1's rmse: 1.00535\n",
      "[148]\ttraining's rmse: 0.931638\tvalid_1's rmse: 1.00521\n",
      "[149]\ttraining's rmse: 0.931075\tvalid_1's rmse: 1.00521\n",
      "[150]\ttraining's rmse: 0.930521\tvalid_1's rmse: 1.00508\n",
      "[151]\ttraining's rmse: 0.93\tvalid_1's rmse: 1.00496\n",
      "[152]\ttraining's rmse: 0.929357\tvalid_1's rmse: 1.0046\n",
      "[153]\ttraining's rmse: 0.928774\tvalid_1's rmse: 1.00455\n",
      "[154]\ttraining's rmse: 0.928273\tvalid_1's rmse: 1.00454\n",
      "[155]\ttraining's rmse: 0.927688\tvalid_1's rmse: 1.00447\n",
      "[156]\ttraining's rmse: 0.927095\tvalid_1's rmse: 1.00436\n",
      "[157]\ttraining's rmse: 0.926587\tvalid_1's rmse: 1.00428\n",
      "[158]\ttraining's rmse: 0.926057\tvalid_1's rmse: 1.00405\n",
      "[159]\ttraining's rmse: 0.925434\tvalid_1's rmse: 1.00389\n",
      "[160]\ttraining's rmse: 0.924938\tvalid_1's rmse: 1.00379\n",
      "[161]\ttraining's rmse: 0.924455\tvalid_1's rmse: 1.00382\n",
      "[162]\ttraining's rmse: 0.92384\tvalid_1's rmse: 1.00348\n",
      "[163]\ttraining's rmse: 0.923344\tvalid_1's rmse: 1.0034\n",
      "[164]\ttraining's rmse: 0.922868\tvalid_1's rmse: 1.00319\n",
      "[165]\ttraining's rmse: 0.922383\tvalid_1's rmse: 1.00318\n",
      "[166]\ttraining's rmse: 0.921824\tvalid_1's rmse: 1.00298\n",
      "[167]\ttraining's rmse: 0.921272\tvalid_1's rmse: 1.00288\n",
      "[168]\ttraining's rmse: 0.920691\tvalid_1's rmse: 1.00281\n",
      "[169]\ttraining's rmse: 0.920219\tvalid_1's rmse: 1.00282\n",
      "[170]\ttraining's rmse: 0.919808\tvalid_1's rmse: 1.00263\n",
      "[171]\ttraining's rmse: 0.919327\tvalid_1's rmse: 1.00259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172]\ttraining's rmse: 0.918829\tvalid_1's rmse: 1.00238\n",
      "[173]\ttraining's rmse: 0.918388\tvalid_1's rmse: 1.00218\n",
      "[174]\ttraining's rmse: 0.917962\tvalid_1's rmse: 1.00198\n",
      "[175]\ttraining's rmse: 0.917406\tvalid_1's rmse: 1.00198\n",
      "[176]\ttraining's rmse: 0.916976\tvalid_1's rmse: 1.00191\n",
      "[177]\ttraining's rmse: 0.916515\tvalid_1's rmse: 1.00186\n",
      "[178]\ttraining's rmse: 0.916105\tvalid_1's rmse: 1.00191\n",
      "[179]\ttraining's rmse: 0.915645\tvalid_1's rmse: 1.00178\n",
      "[180]\ttraining's rmse: 0.91523\tvalid_1's rmse: 1.00158\n",
      "[181]\ttraining's rmse: 0.914807\tvalid_1's rmse: 1.00149\n",
      "[182]\ttraining's rmse: 0.914389\tvalid_1's rmse: 1.00149\n",
      "[183]\ttraining's rmse: 0.913944\tvalid_1's rmse: 1.0013\n",
      "[184]\ttraining's rmse: 0.913497\tvalid_1's rmse: 1.00134\n",
      "[185]\ttraining's rmse: 0.913038\tvalid_1's rmse: 1.00128\n",
      "[186]\ttraining's rmse: 0.912658\tvalid_1's rmse: 1.0012\n",
      "[187]\ttraining's rmse: 0.912285\tvalid_1's rmse: 1.00124\n",
      "[188]\ttraining's rmse: 0.911823\tvalid_1's rmse: 1.001\n",
      "[189]\ttraining's rmse: 0.911411\tvalid_1's rmse: 1.00102\n",
      "[190]\ttraining's rmse: 0.910984\tvalid_1's rmse: 1.00107\n",
      "[191]\ttraining's rmse: 0.910634\tvalid_1's rmse: 1.00107\n",
      "[192]\ttraining's rmse: 0.91018\tvalid_1's rmse: 1.00101\n",
      "[193]\ttraining's rmse: 0.909803\tvalid_1's rmse: 1.00109\n",
      "[194]\ttraining's rmse: 0.909255\tvalid_1's rmse: 1.00073\n",
      "[195]\ttraining's rmse: 0.908784\tvalid_1's rmse: 1.00065\n",
      "[196]\ttraining's rmse: 0.908358\tvalid_1's rmse: 1.00051\n",
      "[197]\ttraining's rmse: 0.907988\tvalid_1's rmse: 1.00041\n",
      "[198]\ttraining's rmse: 0.90758\tvalid_1's rmse: 1.00034\n",
      "[199]\ttraining's rmse: 0.907087\tvalid_1's rmse: 1.00019\n",
      "[200]\ttraining's rmse: 0.906743\tvalid_1's rmse: 1.00013\n",
      "[201]\ttraining's rmse: 0.906382\tvalid_1's rmse: 1.00003\n",
      "[202]\ttraining's rmse: 0.906005\tvalid_1's rmse: 1.00011\n",
      "[203]\ttraining's rmse: 0.905549\tvalid_1's rmse: 1.00004\n",
      "[204]\ttraining's rmse: 0.905204\tvalid_1's rmse: 0.999967\n",
      "[205]\ttraining's rmse: 0.904819\tvalid_1's rmse: 0.999825\n",
      "[206]\ttraining's rmse: 0.904492\tvalid_1's rmse: 0.999783\n",
      "[207]\ttraining's rmse: 0.904167\tvalid_1's rmse: 0.999867\n",
      "[208]\ttraining's rmse: 0.90372\tvalid_1's rmse: 0.999857\n",
      "[209]\ttraining's rmse: 0.903247\tvalid_1's rmse: 0.999892\n",
      "[210]\ttraining's rmse: 0.902904\tvalid_1's rmse: 0.99991\n",
      "[211]\ttraining's rmse: 0.902437\tvalid_1's rmse: 0.999847\n",
      "[212]\ttraining's rmse: 0.902017\tvalid_1's rmse: 1.00002\n",
      "[213]\ttraining's rmse: 0.901562\tvalid_1's rmse: 1.00012\n",
      "[214]\ttraining's rmse: 0.9012\tvalid_1's rmse: 0.999877\n",
      "[215]\ttraining's rmse: 0.900758\tvalid_1's rmse: 0.999895\n",
      "[216]\ttraining's rmse: 0.900341\tvalid_1's rmse: 0.999814\n",
      "[217]\ttraining's rmse: 0.90004\tvalid_1's rmse: 0.999736\n",
      "[218]\ttraining's rmse: 0.899634\tvalid_1's rmse: 0.999529\n",
      "[219]\ttraining's rmse: 0.899209\tvalid_1's rmse: 0.99962\n",
      "[220]\ttraining's rmse: 0.898863\tvalid_1's rmse: 0.999537\n",
      "[221]\ttraining's rmse: 0.898518\tvalid_1's rmse: 0.999556\n",
      "[222]\ttraining's rmse: 0.898134\tvalid_1's rmse: 0.999435\n",
      "[223]\ttraining's rmse: 0.897717\tvalid_1's rmse: 0.99944\n",
      "[224]\ttraining's rmse: 0.897357\tvalid_1's rmse: 0.999511\n",
      "[225]\ttraining's rmse: 0.897009\tvalid_1's rmse: 0.999549\n",
      "[226]\ttraining's rmse: 0.896694\tvalid_1's rmse: 0.999488\n",
      "[227]\ttraining's rmse: 0.896317\tvalid_1's rmse: 0.999418\n",
      "[228]\ttraining's rmse: 0.89592\tvalid_1's rmse: 0.999376\n",
      "[229]\ttraining's rmse: 0.895684\tvalid_1's rmse: 0.999353\n",
      "[230]\ttraining's rmse: 0.895328\tvalid_1's rmse: 0.999271\n",
      "[231]\ttraining's rmse: 0.895005\tvalid_1's rmse: 0.999369\n",
      "[232]\ttraining's rmse: 0.894616\tvalid_1's rmse: 0.999322\n",
      "[233]\ttraining's rmse: 0.894312\tvalid_1's rmse: 0.999303\n",
      "[234]\ttraining's rmse: 0.893935\tvalid_1's rmse: 0.999221\n",
      "[235]\ttraining's rmse: 0.893577\tvalid_1's rmse: 0.999303\n",
      "[236]\ttraining's rmse: 0.893253\tvalid_1's rmse: 0.99933\n",
      "[237]\ttraining's rmse: 0.892933\tvalid_1's rmse: 0.999327\n",
      "[238]\ttraining's rmse: 0.892551\tvalid_1's rmse: 0.999361\n",
      "[239]\ttraining's rmse: 0.892139\tvalid_1's rmse: 0.999391\n",
      "[240]\ttraining's rmse: 0.891783\tvalid_1's rmse: 0.999477\n",
      "[241]\ttraining's rmse: 0.891342\tvalid_1's rmse: 0.99942\n",
      "[242]\ttraining's rmse: 0.890988\tvalid_1's rmse: 0.999332\n",
      "[243]\ttraining's rmse: 0.890652\tvalid_1's rmse: 0.999298\n",
      "[244]\ttraining's rmse: 0.890391\tvalid_1's rmse: 0.999325\n",
      "[245]\ttraining's rmse: 0.890001\tvalid_1's rmse: 0.999128\n",
      "[246]\ttraining's rmse: 0.889654\tvalid_1's rmse: 0.999053\n",
      "[247]\ttraining's rmse: 0.889352\tvalid_1's rmse: 0.999155\n",
      "[248]\ttraining's rmse: 0.888997\tvalid_1's rmse: 0.999066\n",
      "[249]\ttraining's rmse: 0.888719\tvalid_1's rmse: 0.998986\n",
      "[250]\ttraining's rmse: 0.888457\tvalid_1's rmse: 0.998916\n",
      "[251]\ttraining's rmse: 0.88816\tvalid_1's rmse: 0.998819\n",
      "[252]\ttraining's rmse: 0.887825\tvalid_1's rmse: 0.998737\n",
      "[253]\ttraining's rmse: 0.887556\tvalid_1's rmse: 0.998674\n",
      "[254]\ttraining's rmse: 0.88727\tvalid_1's rmse: 0.998694\n",
      "[255]\ttraining's rmse: 0.886955\tvalid_1's rmse: 0.99862\n",
      "[256]\ttraining's rmse: 0.88663\tvalid_1's rmse: 0.99862\n",
      "[257]\ttraining's rmse: 0.886302\tvalid_1's rmse: 0.998627\n",
      "[258]\ttraining's rmse: 0.88602\tvalid_1's rmse: 0.998555\n",
      "[259]\ttraining's rmse: 0.885704\tvalid_1's rmse: 0.998667\n",
      "[260]\ttraining's rmse: 0.885417\tvalid_1's rmse: 0.998681\n",
      "[261]\ttraining's rmse: 0.885133\tvalid_1's rmse: 0.998477\n",
      "[262]\ttraining's rmse: 0.884803\tvalid_1's rmse: 0.998411\n",
      "[263]\ttraining's rmse: 0.884573\tvalid_1's rmse: 0.998505\n",
      "[264]\ttraining's rmse: 0.884338\tvalid_1's rmse: 0.998619\n",
      "[265]\ttraining's rmse: 0.884079\tvalid_1's rmse: 0.998537\n",
      "[266]\ttraining's rmse: 0.883751\tvalid_1's rmse: 0.998573\n",
      "[267]\ttraining's rmse: 0.883393\tvalid_1's rmse: 0.998695\n",
      "[268]\ttraining's rmse: 0.883108\tvalid_1's rmse: 0.998586\n",
      "[269]\ttraining's rmse: 0.882865\tvalid_1's rmse: 0.998622\n",
      "[270]\ttraining's rmse: 0.882633\tvalid_1's rmse: 0.998663\n",
      "[271]\ttraining's rmse: 0.88234\tvalid_1's rmse: 0.998608\n",
      "[272]\ttraining's rmse: 0.88204\tvalid_1's rmse: 0.998609\n",
      "[273]\ttraining's rmse: 0.88171\tvalid_1's rmse: 0.998623\n",
      "[274]\ttraining's rmse: 0.881402\tvalid_1's rmse: 0.998474\n",
      "[275]\ttraining's rmse: 0.881081\tvalid_1's rmse: 0.998401\n",
      "[276]\ttraining's rmse: 0.880756\tvalid_1's rmse: 0.998341\n",
      "[277]\ttraining's rmse: 0.880499\tvalid_1's rmse: 0.998376\n",
      "[278]\ttraining's rmse: 0.880158\tvalid_1's rmse: 0.998348\n",
      "[279]\ttraining's rmse: 0.87993\tvalid_1's rmse: 0.99842\n",
      "[280]\ttraining's rmse: 0.879571\tvalid_1's rmse: 0.998484\n",
      "[281]\ttraining's rmse: 0.879258\tvalid_1's rmse: 0.998447\n",
      "[282]\ttraining's rmse: 0.879072\tvalid_1's rmse: 0.99836\n",
      "[283]\ttraining's rmse: 0.878808\tvalid_1's rmse: 0.99841\n",
      "[284]\ttraining's rmse: 0.87855\tvalid_1's rmse: 0.998384\n",
      "[285]\ttraining's rmse: 0.878244\tvalid_1's rmse: 0.998277\n",
      "[286]\ttraining's rmse: 0.878062\tvalid_1's rmse: 0.998357\n",
      "[287]\ttraining's rmse: 0.87773\tvalid_1's rmse: 0.998322\n",
      "[288]\ttraining's rmse: 0.877441\tvalid_1's rmse: 0.998202\n",
      "[289]\ttraining's rmse: 0.87714\tvalid_1's rmse: 0.998302\n",
      "[290]\ttraining's rmse: 0.876817\tvalid_1's rmse: 0.998226\n",
      "[291]\ttraining's rmse: 0.876563\tvalid_1's rmse: 0.998063\n",
      "[292]\ttraining's rmse: 0.876293\tvalid_1's rmse: 0.998167\n",
      "[293]\ttraining's rmse: 0.875993\tvalid_1's rmse: 0.998132\n",
      "[294]\ttraining's rmse: 0.875813\tvalid_1's rmse: 0.99806\n",
      "[295]\ttraining's rmse: 0.875564\tvalid_1's rmse: 0.998047\n",
      "[296]\ttraining's rmse: 0.875294\tvalid_1's rmse: 0.998088\n",
      "[297]\ttraining's rmse: 0.875\tvalid_1's rmse: 0.998122\n",
      "[298]\ttraining's rmse: 0.874794\tvalid_1's rmse: 0.998168\n",
      "[299]\ttraining's rmse: 0.874523\tvalid_1's rmse: 0.998054\n",
      "[300]\ttraining's rmse: 0.874305\tvalid_1's rmse: 0.998128\n",
      "[301]\ttraining's rmse: 0.874075\tvalid_1's rmse: 0.998204\n",
      "[302]\ttraining's rmse: 0.873802\tvalid_1's rmse: 0.99811\n",
      "[303]\ttraining's rmse: 0.873519\tvalid_1's rmse: 0.99802\n",
      "[304]\ttraining's rmse: 0.873268\tvalid_1's rmse: 0.997972\n",
      "[305]\ttraining's rmse: 0.873049\tvalid_1's rmse: 0.997953\n",
      "[306]\ttraining's rmse: 0.872792\tvalid_1's rmse: 0.997943\n",
      "[307]\ttraining's rmse: 0.872547\tvalid_1's rmse: 0.998026\n",
      "[308]\ttraining's rmse: 0.872289\tvalid_1's rmse: 0.998086\n",
      "[309]\ttraining's rmse: 0.871974\tvalid_1's rmse: 0.997997\n",
      "[310]\ttraining's rmse: 0.871748\tvalid_1's rmse: 0.997915\n",
      "[311]\ttraining's rmse: 0.871459\tvalid_1's rmse: 0.99788\n",
      "[312]\ttraining's rmse: 0.87124\tvalid_1's rmse: 0.997989\n",
      "[313]\ttraining's rmse: 0.871067\tvalid_1's rmse: 0.998083\n",
      "[314]\ttraining's rmse: 0.870833\tvalid_1's rmse: 0.99817\n",
      "[315]\ttraining's rmse: 0.870577\tvalid_1's rmse: 0.998232\n",
      "[316]\ttraining's rmse: 0.870278\tvalid_1's rmse: 0.99824\n",
      "[317]\ttraining's rmse: 0.870087\tvalid_1's rmse: 0.99835\n",
      "[318]\ttraining's rmse: 0.869867\tvalid_1's rmse: 0.998313\n",
      "[319]\ttraining's rmse: 0.86963\tvalid_1's rmse: 0.998317\n",
      "[320]\ttraining's rmse: 0.869443\tvalid_1's rmse: 0.998332\n",
      "[321]\ttraining's rmse: 0.869259\tvalid_1's rmse: 0.998265\n",
      "[322]\ttraining's rmse: 0.869015\tvalid_1's rmse: 0.998228\n",
      "[323]\ttraining's rmse: 0.868815\tvalid_1's rmse: 0.998219\n",
      "[324]\ttraining's rmse: 0.868584\tvalid_1's rmse: 0.998194\n",
      "[325]\ttraining's rmse: 0.868389\tvalid_1's rmse: 0.998243\n",
      "[326]\ttraining's rmse: 0.868171\tvalid_1's rmse: 0.998203\n",
      "[327]\ttraining's rmse: 0.867947\tvalid_1's rmse: 0.998254\n",
      "[328]\ttraining's rmse: 0.867715\tvalid_1's rmse: 0.998211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329]\ttraining's rmse: 0.867464\tvalid_1's rmse: 0.99817\n",
      "[330]\ttraining's rmse: 0.867171\tvalid_1's rmse: 0.998234\n",
      "[331]\ttraining's rmse: 0.866947\tvalid_1's rmse: 0.998149\n",
      "[332]\ttraining's rmse: 0.866776\tvalid_1's rmse: 0.998038\n",
      "[333]\ttraining's rmse: 0.866515\tvalid_1's rmse: 0.998123\n",
      "[334]\ttraining's rmse: 0.866273\tvalid_1's rmse: 0.99813\n",
      "[335]\ttraining's rmse: 0.86604\tvalid_1's rmse: 0.998062\n",
      "[336]\ttraining's rmse: 0.865815\tvalid_1's rmse: 0.998063\n",
      "[337]\ttraining's rmse: 0.865521\tvalid_1's rmse: 0.998049\n",
      "[338]\ttraining's rmse: 0.865318\tvalid_1's rmse: 0.998169\n",
      "[339]\ttraining's rmse: 0.865108\tvalid_1's rmse: 0.998237\n",
      "[340]\ttraining's rmse: 0.864794\tvalid_1's rmse: 0.998259\n",
      "[341]\ttraining's rmse: 0.864556\tvalid_1's rmse: 0.99828\n",
      "[342]\ttraining's rmse: 0.864344\tvalid_1's rmse: 0.99829\n",
      "[343]\ttraining's rmse: 0.864166\tvalid_1's rmse: 0.998367\n",
      "[344]\ttraining's rmse: 0.863987\tvalid_1's rmse: 0.998442\n",
      "[345]\ttraining's rmse: 0.863771\tvalid_1's rmse: 0.998423\n",
      "[346]\ttraining's rmse: 0.863582\tvalid_1's rmse: 0.9984\n",
      "[347]\ttraining's rmse: 0.863416\tvalid_1's rmse: 0.998434\n",
      "[348]\ttraining's rmse: 0.863146\tvalid_1's rmse: 0.998486\n",
      "[349]\ttraining's rmse: 0.862946\tvalid_1's rmse: 0.99849\n",
      "[350]\ttraining's rmse: 0.862711\tvalid_1's rmse: 0.998556\n",
      "[351]\ttraining's rmse: 0.862496\tvalid_1's rmse: 0.998491\n",
      "[352]\ttraining's rmse: 0.862275\tvalid_1's rmse: 0.9986\n",
      "[353]\ttraining's rmse: 0.862101\tvalid_1's rmse: 0.998678\n",
      "[354]\ttraining's rmse: 0.861848\tvalid_1's rmse: 0.998633\n",
      "[355]\ttraining's rmse: 0.861574\tvalid_1's rmse: 0.998597\n",
      "[356]\ttraining's rmse: 0.861365\tvalid_1's rmse: 0.998635\n",
      "[357]\ttraining's rmse: 0.861196\tvalid_1's rmse: 0.998628\n",
      "[358]\ttraining's rmse: 0.86082\tvalid_1's rmse: 0.998723\n",
      "[359]\ttraining's rmse: 0.860644\tvalid_1's rmse: 0.99881\n",
      "[360]\ttraining's rmse: 0.860446\tvalid_1's rmse: 0.998716\n",
      "[361]\ttraining's rmse: 0.860312\tvalid_1's rmse: 0.99862\n",
      "[362]\ttraining's rmse: 0.860143\tvalid_1's rmse: 0.998598\n",
      "[363]\ttraining's rmse: 0.859776\tvalid_1's rmse: 0.998628\n",
      "[364]\ttraining's rmse: 0.859542\tvalid_1's rmse: 0.998581\n",
      "[365]\ttraining's rmse: 0.859329\tvalid_1's rmse: 0.998599\n",
      "[366]\ttraining's rmse: 0.85912\tvalid_1's rmse: 0.99867\n",
      "[367]\ttraining's rmse: 0.858969\tvalid_1's rmse: 0.998582\n",
      "[368]\ttraining's rmse: 0.85868\tvalid_1's rmse: 0.998585\n",
      "[369]\ttraining's rmse: 0.858517\tvalid_1's rmse: 0.998749\n",
      "[370]\ttraining's rmse: 0.858286\tvalid_1's rmse: 0.99868\n",
      "[371]\ttraining's rmse: 0.858079\tvalid_1's rmse: 0.998618\n",
      "[372]\ttraining's rmse: 0.857943\tvalid_1's rmse: 0.998551\n",
      "[373]\ttraining's rmse: 0.857714\tvalid_1's rmse: 0.998676\n",
      "[374]\ttraining's rmse: 0.857456\tvalid_1's rmse: 0.998677\n",
      "[375]\ttraining's rmse: 0.857176\tvalid_1's rmse: 0.998709\n",
      "[376]\ttraining's rmse: 0.857012\tvalid_1's rmse: 0.998795\n",
      "[377]\ttraining's rmse: 0.856865\tvalid_1's rmse: 0.998784\n",
      "[378]\ttraining's rmse: 0.856682\tvalid_1's rmse: 0.99879\n",
      "[379]\ttraining's rmse: 0.856479\tvalid_1's rmse: 0.998748\n",
      "[380]\ttraining's rmse: 0.8563\tvalid_1's rmse: 0.998791\n",
      "[381]\ttraining's rmse: 0.85611\tvalid_1's rmse: 0.998734\n",
      "[382]\ttraining's rmse: 0.855965\tvalid_1's rmse: 0.998851\n",
      "[383]\ttraining's rmse: 0.85575\tvalid_1's rmse: 0.998823\n",
      "[384]\ttraining's rmse: 0.855621\tvalid_1's rmse: 0.998893\n",
      "[385]\ttraining's rmse: 0.85529\tvalid_1's rmse: 0.99885\n",
      "[386]\ttraining's rmse: 0.855147\tvalid_1's rmse: 0.998885\n",
      "[387]\ttraining's rmse: 0.854914\tvalid_1's rmse: 0.998791\n",
      "[388]\ttraining's rmse: 0.854728\tvalid_1's rmse: 0.998774\n",
      "[389]\ttraining's rmse: 0.854541\tvalid_1's rmse: 0.998831\n",
      "[390]\ttraining's rmse: 0.854371\tvalid_1's rmse: 0.998854\n",
      "[391]\ttraining's rmse: 0.854271\tvalid_1's rmse: 0.998838\n",
      "[392]\ttraining's rmse: 0.854131\tvalid_1's rmse: 0.998849\n",
      "[393]\ttraining's rmse: 0.853916\tvalid_1's rmse: 0.998808\n",
      "[394]\ttraining's rmse: 0.853569\tvalid_1's rmse: 0.998863\n",
      "[395]\ttraining's rmse: 0.853418\tvalid_1's rmse: 0.998891\n",
      "[396]\ttraining's rmse: 0.853284\tvalid_1's rmse: 0.998906\n",
      "[397]\ttraining's rmse: 0.853196\tvalid_1's rmse: 0.998903\n",
      "[398]\ttraining's rmse: 0.853017\tvalid_1's rmse: 0.998825\n",
      "[399]\ttraining's rmse: 0.852853\tvalid_1's rmse: 0.998786\n",
      "[400]\ttraining's rmse: 0.852681\tvalid_1's rmse: 0.998849\n",
      "[401]\ttraining's rmse: 0.852414\tvalid_1's rmse: 0.998896\n",
      "[402]\ttraining's rmse: 0.852268\tvalid_1's rmse: 0.998976\n",
      "[403]\ttraining's rmse: 0.852132\tvalid_1's rmse: 0.99905\n",
      "[404]\ttraining's rmse: 0.851923\tvalid_1's rmse: 0.999106\n",
      "[405]\ttraining's rmse: 0.851703\tvalid_1's rmse: 0.999201\n",
      "[406]\ttraining's rmse: 0.851542\tvalid_1's rmse: 0.999243\n",
      "[407]\ttraining's rmse: 0.851411\tvalid_1's rmse: 0.999244\n",
      "[408]\ttraining's rmse: 0.851214\tvalid_1's rmse: 0.999287\n",
      "[409]\ttraining's rmse: 0.851027\tvalid_1's rmse: 0.999306\n",
      "[410]\ttraining's rmse: 0.850894\tvalid_1's rmse: 0.999381\n",
      "[411]\ttraining's rmse: 0.850712\tvalid_1's rmse: 0.99936\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's rmse: 0.871459\tvalid_1's rmse: 0.99788\n"
     ]
    }
   ],
   "source": [
    "num_round = 1000\n",
    "\n",
    "clf = lgb.train(params,\n",
    "                train_data,\n",
    "                num_round,\n",
    "                valid_sets=[train_data, val_data],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5246363303586942"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "cohen_kappa_score(y_val, np.round(y_pred,0), weights= 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(X_val)\n",
    "test_sub['accuracy_group'] = pd.Series(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

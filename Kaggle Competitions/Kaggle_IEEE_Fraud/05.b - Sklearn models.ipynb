{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.fraud_modeller import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickleObjects import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded!\n",
      "Object loaded!\n",
      "Object loaded!\n",
      "Object loaded!\n"
     ]
    }
   ],
   "source": [
    "path = './Data/'\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadObjects(path+'X_train'),loadObjects(path+'X_test'),loadObjects(path+'y_train'),loadObjects(path+'y_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([455902,  16530])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113975,   4133])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train_scaled, y_train.astype(int))\n",
    "y_pred=clf.predict_proba(X_test_scaled)[:, 1]\n",
    "clf_roc=roc_auc_score(y_test.astype(int),y_pred)\n",
    "clf_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "\n",
    "\n",
    "LR = Pipeline([('LR', clf)])\n",
    "\n",
    "penalties = ['l1', 'l2']\n",
    "Cs = np.logspace(-4, 1, 20)\n",
    "solvers = ['liblinear']\n",
    "\n",
    "parameters = [{'LR__penalty':penalty, 'LR__C': c, 'LR__solver':solver} \n",
    "              for penalty in penalties\n",
    "              for c in Cs\n",
    "              for solver in solvers]\n",
    "\n",
    "print('Number of parameters: ' , len(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTuner(pipeline=LR,parameters=parameters[:10], X_train=X_train_scaled, \n",
    "                    y_train=y_train.astype(int), X_valid=X_test_scaled,\n",
    "                    y_valid=y_test.astype(int), eval_metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "            max_iter=-1, probability=True, random_state=0, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "\n",
    "\n",
    "SVM = Pipeline([('SVM', clf)])\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['rbf','poly','linear']\n",
    "\n",
    "          \n",
    "parameters = [{'SVM__gamma':gamma, 'SVM__C': c, 'SVM__kernel':kernel} \n",
    "              for gamma in gammas\n",
    "              for c in Cs\n",
    "              for kernel in kernels]\n",
    "          \n",
    "print('Number of parameters: ' , len(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTuner(pipeline=SVM,parameters=parameters[:5], X_train=X_train_scaled, \n",
    "                    y_train=y_train.astype(int), X_valid=X_test_scaled,\n",
    "                    y_valid=y_test.astype(int), eval_metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "RF = Pipeline([('RF', clf)])\n",
    "\n",
    "bootstraps = [True, False]\n",
    "max_depths = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_leafs = [1, 2, 4]\n",
    "min_samples_splits = [2, 5, 10]\n",
    "n_estimators = np.arange(10,500,50)\n",
    "criteria = ['gini','entropy']\n",
    "\n",
    "          \n",
    "parameters = [{'RF__bootstrap': bootstrap,\n",
    "               'RF__max_depth': depth,\n",
    "               'RF__max_features': feat,\n",
    "               'RF__min_samples_leaf': leaf,\n",
    "               'RF__min_samples_split': split,\n",
    "               'RF__n_estimators': estimators,\n",
    "               'RF__criterion': criterion}\n",
    "\n",
    "              for bootstrap in bootstraps\n",
    "              for depth in max_depths\n",
    "              for feat in max_features\n",
    "              for leaf in min_samples_leafs\n",
    "              for split in min_samples_splits\n",
    "              for estimators in n_estimators\n",
    "              for criterion in criteria]\n",
    "          \n",
    "print('Number of parameters: ' , len(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM SAMPLING\n",
    "random_inds = np.random.RandomState(20).randint(0,len(parameters),size=100)\n",
    "\n",
    "parameters = np.array(parameters)\n",
    "random_params = parameters[random_inds]\n",
    "\n",
    "print('Number of random parameters: ' , len(random_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTuner(pipeline=RF,parameters=random_params, X_train=X_train_scaled, \n",
    "                    y_train=y_train.astype(int), X_valid=X_test_scaled,\n",
    "                    y_valid=y_test.astype(int), eval_metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3840\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(\n",
    "             learning_rate =0.1,\n",
    "             n_estimators=1000,\n",
    "             max_depth=5,\n",
    "             min_child_weight=1,\n",
    "             gamma=0,\n",
    "             subsample=0.8,\n",
    "             colsample_bytree=0.8,\n",
    "             objective= 'binary:logistic',\n",
    "             nthread=10,\n",
    "             scale_pos_weight=1,\n",
    "             seed=27)\n",
    "\n",
    "\n",
    "XGB = Pipeline([('XGB', clf)])\n",
    "\n",
    "\n",
    "learning_rates = [0.05, 0.10, 0.15]\n",
    "max_depths = [6, 8, 10, 12, 15]\n",
    "min_child_weights = [ 1, 3, 5, 7 ]\n",
    "gammas = [ 0.1, 0.2 , 0.3, 0.4 ]\n",
    "colsample_bytrees = [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "n_estimators = np.arange(100,300,50)\n",
    "\n",
    "\n",
    "\n",
    "parameters = [{  'XGB__learning_rate'    : learning_rate,\n",
    "                 'XGB__max_depth'        : depth,\n",
    "                 'XGB__min_child_weight' : min_child_weight,\n",
    "                 'XGB__gamma'            : gamma,\n",
    "                 'XGB__colsample_bytree' : colsample_bytree,\n",
    "                 'XGB__n_estimators' : estimators}\n",
    "\n",
    "              for learning_rate in learning_rates\n",
    "              for depth in max_depths\n",
    "              for min_child_weight in min_child_weights\n",
    "              for gamma in gammas\n",
    "              for colsample_bytree in colsample_bytrees\n",
    "              for estimators in n_estimators]\n",
    "          \n",
    "print('Number of parameters: ' , len(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random parameters:  20\n"
     ]
    }
   ],
   "source": [
    "#RANDOM SAMPLING\n",
    "random_inds = np.unique(np.random.RandomState(20)\\\n",
    "                .randint(0,len(parameters),size=20))\n",
    "\n",
    "parameters = np.array(parameters)\n",
    "random_params = parameters[random_inds]\n",
    "\n",
    "print('Number of random parameters: ' , len(random_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.random.RandomState(30).randint(0,X_train_scaled.shape[0],size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [44:10<00:00, 161.56s/it] \n"
     ]
    }
   ],
   "source": [
    "model = ModelTuner(pipeline=XGB,parameters=random_params, \n",
    "                   X_train=X_train_scaled, \n",
    "                    y_train=y_train.astype(int), \n",
    "                    X_valid=X_test_scaled,\n",
    "                    y_valid=y_test.astype(int), eval_metric=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343498270146494"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('XGB', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.5, gamma=0.1,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=15,\n",
       "       min_child_weight=5, missing=None, n_estimators=150, n_jobs=1,\n",
       "       nthread=10, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=None,\n",
       "       subsample=0.8, verbosity=1))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train_scaled,X_test_scaled),axis=0)\n",
    "y = np.concatenate((y_train.astype(int),y_test.astype(int)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('XGB', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.5, gamma=0.1,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=15,\n",
       "       min_child_weight=5, missing=None, n_estimators=150, n_jobs=1,\n",
       "       nthread=10, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=None,\n",
       "       subsample=0.8, verbosity=1))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_model.set_params(**model.best_params).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded!\n"
     ]
    }
   ],
   "source": [
    "X_test_sub = loadObjects(path+'X_test_comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sub_scaled = scaler.transform(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.best_model.predict_proba(X_test_sub_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub = pd.read_csv('./Data/test_transaction.csv',\n",
    "                       usecols = ['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub['isFraud'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.005749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.011596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.003449\n",
       "1        3663550  0.005749\n",
       "2        3663551  0.011596"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub.to_csv('./Data/codenames_sub_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
